# Application Settings
DEBUG=false
LOG_LEVEL=INFO

# Server Configuration
HOST=0.0.0.0
PORT=8000

# Main LLM Configuration - Used for production responses
MODEL_PROVIDER=gemini
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-flash-preview-05-20
GEMINI_TEMPERATURE=0.7
GEMINI_MAX_TOKENS=2048

# Evaluation LLM Configuration - Used for evaluation only
EVAL_MODEL_PROVIDER=gemini
EVAL_GEMINI_MODEL=gemini-1.5-flash-8b
EVAL_GEMINI_TEMPERATURE=0.3
EVAL_GEMINI_MAX_TOKENS=4096

# Pinecone Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_environment
PINECONE_INDEX_NAME=your_index_name

# Embedding Configuration
EMBEDDING_MODEL=llama-text-embed-v2
EMBEDDING_DIMENSION=1024

# Document Processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Slack Configuration (if ENABLE_SLACK_NOTIFICATIONS=true)
SLACK_WEBHOOK_URL=your_slack_webhook_url
SLACK_CHANNEL=#manufacturing-alerts

# MES Configuration (if ENABLE_MES_INTEGRATION=true)
MES_API_URL=https://mes-api.example.com
MES_API_KEY=your_mes_api_key

# ERP Configuration (if ENABLE_ERP_INTEGRATION=true)
ERP_API_URL=https://erp-api.example.com
ERP_API_KEY=your_erp_api_key

# Feature Flags
ENABLE_SLACK_NOTIFICATIONS=false
ENABLE_MES_INTEGRATION=true
ENABLE_ERP_INTEGRATION=true

# Optional: LangSmith configuration for debugging
# LANGCHAIN_TRACING_V2=false
# LANGCHAIN_API_KEY=your_langsmith_api_key
# LANGCHAIN_PROJECT=Manufacturing Agent MVP
# LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# Optional: LangSmith configuration for debugging
# LANGCHAIN_TRACING_V2=false
# LANGCHAIN_API_KEY=your_langsmith_api_key
# LANGCHAIN_PROJECT=Manufacturing Agent MVP
# LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
